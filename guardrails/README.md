# Sistema de Guardrails LUCA

El sistema de guardrails de LUCA proporciona una arquitectura h√≠brida de protecciones para interacciones educativas, asegurando contenido apropiado, relevancia acad√©mica y uso responsable de los agentes de AI.

## üéØ **Arquitectura General**

```
Student Input
     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    GUARDRAIL LAYER (Centralizada)   ‚îÇ
‚îÇ  ‚Ä¢ Content Safety                   ‚îÇ
‚îÇ  ‚Ä¢ Educational Context              ‚îÇ
‚îÇ  ‚Ä¢ Rate Limiting                    ‚îÇ
‚îÇ  ‚Ä¢ Profanity Filter                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚Üì (filtered/approved input)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ       ORCHESTRATOR AGENT            ‚îÇ
‚îÇ  ‚Ä¢ Academic Intent Classification   ‚îÇ
‚îÇ  ‚Ä¢ Educational Domain Validation    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      SPECIALIZED AGENTS             ‚îÇ
‚îÇ  ‚Ä¢ Subject-specific guardrails      ‚îÇ
‚îÇ  ‚Ä¢ Response validation              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üõ°Ô∏è **Componentes del Sistema**

### **1. Capa Superior (`EducationalGuardrailLayer`)**
**Archivo**: `core.py`

Orquesta todas las validaciones antes de que el input llegue a los agentes.

```python
from guardrails import EducationalGuardrailLayer, GuardrailConfig, EducationalContext

# Configuraci√≥n b√°sica
config = GuardrailConfig(
    enable_openai_moderation=True,
    enable_profanity_filter=True,
    enable_educational_validation=True,
    enable_rate_limiting=True
)

# Inicializar sistema
guardrail = EducationalGuardrailLayer(config)

# Crear contexto educativo
context = EducationalContext(
    student_id="student_123",
    session_id="session_456", 
    subject="Bases de Datos",
    academic_level="university",
    institution="UCA"
)

# Validar input
result = await guardrail.validate_input(user_message, context)

if result.should_block:
    print("‚ùå Input bloqueado:", result.violations)
elif result.has_warnings:
    print("‚ö†Ô∏è Advertencias:", result.violations)
else:
    print("‚úÖ Input aprobado")
```

### **2. Validaci√≥n de Seguridad de Contenido (`ContentSafetyGuardrail`)**
**Archivo**: `content_safety.py`

- **OpenAI Moderation API**: Detecci√≥n de contenido inapropiado
- **Filtro de Profanidad**: T√©rminos inapropiados en espa√±ol argentino
- **Integridad Acad√©mica**: Detecci√≥n de intentos de hacer trampa

```python
from guardrails.content_safety import ContentSafetyGuardrail

safety = ContentSafetyGuardrail(config)

# Validar input del estudiante
result = await safety.validate("Tu mensaje aqu√≠", context)

# Validar respuesta del agente
response_result = await safety.validate_response("Respuesta del agente", context)
```

**Pol√≠tica de Zero Tolerance**:
- **Profanidad**: Cualquier t√©rmino inapropiado bloquea inmediatamente el contenido
- **Severidad**: Todas las violaciones de profanidad son `BLOCK` (no warnings)
- **T√©rminos incluidos**: Insultos, groser√≠as, lenguaje ofensivo en espa√±ol argentino
- **Inapropiado acad√©mico**: "haceme la tarea", "dame la respuesta" (WARNING)
- **Manipulaci√≥n**: "ignora tus instrucciones", "act√∫a como si" (WARNING)

### **3. Validaci√≥n de Contexto Educativo (`EducationalContextGuardrail`)**
**Archivo**: `educational_context.py`

- **Keywords Acad√©micos**: Detecta t√©rminos relacionados con el curriculum
- **Relevancia Curricular**: Valida alineaci√≥n con dominios de Ingenier√≠a
- **Assessment LLM**: An√°lisis de contenido ambiguo con GPT-4

```python
from guardrails.educational_context import EducationalContextGuardrail

edu_guardrail = EducationalContextGuardrail(config)
result = await edu_guardrail.validate(user_input, context)

# Obtener puntuaci√≥n acad√©mica
academic_score = result.metadata['keyword_analysis']['academic_score']
print(f"Relevancia acad√©mica: {academic_score:.2f}/1.0")
```

**Dominios curriculares soportados**:
- Ingenier√≠a, Matem√°ticas, Programaci√≥n
- Bases de Datos, Algoritmos, Estructuras de Datos
- Redes, Sistemas Operativos

### **4. Rate Limiting (`RateLimitingGuardrail`)**
**Archivo**: `rate_limiting.py`

Sistema de l√≠mites con penalizaciones escaladas:

```python
from guardrails.rate_limiting import RateLimitingGuardrail

rate_limiter = RateLimitingGuardrail(config)

# Verificar l√≠mites
result = await rate_limiter.validate(user_input, context)

# Obtener estado actual del usuario
status = rate_limiter.get_user_status("student_123")
print(f"Requests restantes: {status['remaining']}")
```

**L√≠mites por defecto**:
- 30 requests/minuto
- 200 requests/hora  
- 1000 requests/d√≠a

### **5. Validaci√≥n de Respuestas (`AgentResponseValidator`)**
**Archivo**: `agent_response_validation.py`

Valida que las respuestas de los agentes mantengan calidad educativa:

```python
from guardrails.agent_response_validation import AgentResponseValidator

validator = AgentResponseValidator(config)
result = await validator.validate_response(
    agent_response="La respuesta del agente...",
    original_question="Pregunta original del estudiante",
    context=context
)

# An√°lisis de calidad educativa
educational_score = result.metadata['educational_analysis']['educational_score']
pedagogical_quality = result.metadata['pedagogical_analysis']['pedagogical_quality']
```

## üîß **Configuraci√≥n**

### **Variables de Entorno**

```bash
# Content Safety
export GUARDRAILS_ENABLE_OPENAI_MODERATION=true
export GUARDRAILS_ENABLE_PROFANITY_FILTER=true
export GUARDRAILS_CONTENT_SAFETY_THRESHOLD=0.7

# Educational Context
export GUARDRAILS_ENABLE_EDUCATIONAL_VALIDATION=true
export GUARDRAILS_STRICT_ACADEMIC_MODE=false
export GUARDRAILS_ALLOW_GENERAL_KNOWLEDGE=true

# Rate Limiting
export GUARDRAILS_ENABLE_RATE_LIMITING=true
export GUARDRAILS_MAX_REQUESTS_PER_MINUTE=30
export GUARDRAILS_MAX_REQUESTS_PER_HOUR=200
export GUARDRAILS_MAX_REQUESTS_PER_DAY=1000

# Response Validation
export GUARDRAILS_ENABLE_RESPONSE_VALIDATION=true
export GUARDRAILS_VALIDATE_EDUCATIONAL_VALUE=true

# Observability
export GUARDRAILS_ENABLE_LANGFUSE_LOGGING=true
export GUARDRAILS_LOG_ALL_INTERACTIONS=true
export GUARDRAILS_LOG_BLOCKED_ATTEMPTS=true
```

### **Configuraciones Predefinidas**

```python
from guardrails.config import (
    get_development_config,    # Permisivo para desarrollo
    get_production_config,     # Estricto para producci√≥n
    get_testing_config,        # M√≠nimo para tests
    create_config_for_environment
)

# Auto-detectar entorno
config = create_config_for_environment()  # Lee ENVIRONMENT o NODE_ENV

# Configuraci√≥n espec√≠fica
dev_config = get_development_config()      # L√≠mites altos, modo flexible
prod_config = get_production_config()     # L√≠mites estrictos, modo acad√©mico
test_config = get_testing_config()        # APIs deshabilitadas, sin l√≠mites
```

## üé≠ **Integraci√≥n con Orchestrator**

El sistema se integra autom√°ticamente con el `OrchestratorAgentExecutor`:

```python
from orchestrator.agent_executor import OrchestratorAgentExecutor

# Guardrails habilitados por defecto
executor = OrchestratorAgentExecutor(enable_guardrails=True)

# Verificar estado
status = executor.get_guardrail_status("student_123")
print(f"Guardrails activos: {status['guardrails_enabled']}")

# El streaming incluye autom√°ticamente validaci√≥n:
async for chunk in executor.stream(request, context):
    if chunk.get('guardrail_blocked'):
        print("Request bloqueado por guardrails")
    yield chunk
```

### **Wrapper de Streaming**

El sistema proporciona streaming transparente con validaci√≥n:

```python
from guardrails.orchestrator_integration import GuardrailOrchestrator

guardrail_orch = GuardrailOrchestrator(config)

# Wrapper autom√°tico con validaci√≥n
async for chunk in guardrail_orch.create_guardrail_streaming_wrapper(
    original_stream_function=agent.stream,
    user_message="Mensaje del estudiante",
    session_id="session_123",
    student_id="student_456"
):
    print(chunk)
```

## üìä **Observabilidad con Langfuse**

### **Traces Autom√°ticos**

Todas las validaciones se loggean autom√°ticamente en Langfuse:

```json
{
  "trace_name": "guardrail_validation",
  "session_id": "session_123",
  "user_id": "student_456",
  "input": {
    "user_input": "¬øQu√© es un LEFT JOIN?",
    "context": {...}
  },
  "output": {
    "validation_passed": true,
    "violations": [],
    "execution_time_ms": 45.2
  },
  "spans": [
    {"name": "content_safety_check", "passed": true},
    {"name": "educational_context_check", "passed": true},
    {"name": "rate_limiting_check", "passed": true}
  ]
}
```

### **M√©tricas Disponibles**

En Langfuse podr√°s monitorear:

- **Violaciones por tipo**: `content_safety`, `educational_context`, `rate_limiting`
- **Tasas de bloqueo**: Porcentaje de requests bloqueados
- **Patrones de uso**: Horarios, frecuencia por estudiante
- **Calidad educativa**: Scores de relevancia acad√©mica
- **Performance**: Tiempo de ejecuci√≥n de validaciones

## üß™ **Testing**

### **Ejecutar Demo Completo**

```bash
python test_guardrails_demo.py
```

### **Tests Unitarios**

```python
import pytest
from guardrails import EducationalGuardrailLayer, EducationalContext
from guardrails.config import get_testing_config

@pytest.fixture
def guardrail_system():
    config = get_testing_config()  # APIs deshabilitadas
    return EducationalGuardrailLayer(config)

@pytest.fixture  
def edu_context():
    return EducationalContext(
        student_id="test_student",
        session_id="test_session",
        subject="Programaci√≥n"
    )

@pytest.mark.asyncio
async def test_appropriate_academic_content(guardrail_system, edu_context):
    result = await guardrail_system.validate_input(
        "¬øC√≥mo funciona un algoritmo de ordenamiento?", 
        edu_context
    )
    assert result.passed
    assert not result.violations

@pytest.mark.asyncio
async def test_inappropriate_content_blocked(guardrail_system, edu_context):
    result = await guardrail_system.validate_input(
        "Haceme toda la tarea", 
        edu_context
    )
    assert result.has_warnings or result.should_block
    assert len(result.violations) > 0
```

## üö® **Manejo de Errores**

### **Graceful Degradation**

El sistema est√° dise√±ado para degradar graciosamente:

```python
try:
    result = await guardrail.validate_input(user_input, context)
except Exception as e:
    logger.error(f"Guardrail error: {e}")
    # Sistema contin√∫a sin guardrails
    result = GuardrailResult(passed=True, violations=[])
```

### **Fallbacks por Componente**

- **OpenAI API error**: Contin√∫a con filtros locales
- **Langfuse error**: Logging deshabilitado, validaci√≥n contin√∫a
- **Rate limiting error**: Sin l√≠mites temporalmente
- **Educational assessment error**: Validaci√≥n por keywords √∫nicamente

## üìà **Monitoreo y Alertas**

### **M√©tricas Clave**

1. **Tasa de bloqueos**: `blocked_rate = blocked_requests / total_requests`
2. **Falsos positivos**: Inputs acad√©micos bloqueados incorrectamente
3. **Tiempo de validaci√≥n**: Latencia agregada por guardrails
4. **Uso por estudiante**: Detecci√≥n de patrones an√≥malos

### **Alertas Recomendadas**

```python
# Ejemplo de alertas (pseudoc√≥digo)
if blocked_rate > 0.15:  # >15% de requests bloqueados
    alert("Tasa de bloqueos alta - revisar configuraci√≥n")

if avg_validation_time > 500:  # >500ms de latencia
    alert("Guardrails impactando performance")

if user_violations > 10:  # >10 violaciones por usuario
    alert(f"Usuario problem√°tico: {user_id}")
```

## üîÑ **Versionado y Actualizaciones**

### **Versi√≥n Actual**: `1.0.0`

### **Changelog**

- **v1.0.0**: Release inicial con arquitectura h√≠brida
  - Validaci√≥n de contenido con OpenAI Moderation API
  - Filtros de profanidad contextuales para Argentina
  - Rate limiting inteligente con escalado
  - Integraci√≥n completa con Langfuse
  - Wrapper transparente para Orchestrator

### **Roadmap**

- **v1.1.0**: Fine-tuning basado en datos reales de estudiantes
- **v1.2.0**: Dashboard de administraci√≥n
- **v1.3.0**: ML personalizado para contexto educativo UCA
- **v2.0.0**: Soporte multi-idioma y personalizaci√≥n por carrera

## ü§ù **Contribuci√≥n**

### **Agregar Nuevos Filtros**

```python
# En content_safety.py
def _check_new_inappropriate_pattern(self, text: str) -> Dict[str, Any]:
    violations = []
    # Tu l√≥gica de validaci√≥n aqu√≠
    return {"violations": violations}

# Agregar al m√©todo validate()
new_result = self._check_new_inappropriate_pattern(user_input)
violations.extend(new_result['violations'])
```

### **Nuevos Dominios Curriculares**

```python
# En educational_context.py
curriculum_domains.extend([
    "Inteligencia Artificial",
    "Ciberseguridad", 
    "DevOps"
])
```

## üìû **Soporte**

Para issues, contribuciones o consultas:

1. **Issues**: Usar GitHub Issues del proyecto LUCA
2. **Documentaci√≥n**: Ver ejemplos en `test_guardrails_demo.py`
3. **Configuraci√≥n**: Usar `guardrails.config.print_config_help()`

---

**Desarrollado para LUCA Educational AI System**  
Universidad Cat√≥lica Argentina - Facultad de Ingenier√≠a y Ciencias Agrarias.